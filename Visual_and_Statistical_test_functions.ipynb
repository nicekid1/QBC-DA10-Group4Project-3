{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T18:03:16.369810Z",
          "start_time": "2025-09-10T18:03:16.359310Z"
        },
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import scipy.stats as stats\n",
        "import warnings\n",
        "import json\n",
        "import re\n",
        "import matplotlib.patches as mpatches\n",
        "from itertools import combinations\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from scipy.stats import chi2_contingency\n",
        "import plotly.graph_objects as go\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Univar Plots"
      ],
      "metadata": {
        "id": "FPrv_vmCVct7"
      },
      "id": "FPrv_vmCVct7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7449c32f72e6b61",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.506358Z",
          "start_time": "2025-09-10T17:55:28.493007Z"
        },
        "id": "f7449c32f72e6b61"
      },
      "outputs": [],
      "source": [
        "def describe_numerical_col(df, col_name):\n",
        "    info = df[[col_name]].describe().to_dict()[col_name]\n",
        "    info['shapiro'] = f'{stats.shapiro(df[col_name])[1]: .5f}'\n",
        "    info['normal'] = float(info['shapiro']) > 0.05\n",
        "    info['missing'] = df[col_name].isna().sum()\n",
        "    info['skew'] = f'{stats.skew(df[col_name]):.5f}'\n",
        "    info['type'] = ('slight ' if info['normal'] else '') + \\\n",
        "                   ('right(positive)' if float(info['skew']) > 0 else 'left(negative)') + '-skew'\n",
        "\n",
        "    fig, ax = plt.subplots(2, 2, figsize=(16, 7), gridspec_kw={'height_ratios': (.85, .15)})\n",
        "    sns.histplot(df[col_name], kde=True, ax=ax[0, 0], color='#55A868')\n",
        "    sns.boxplot(df[col_name], orient='h', ax=ax[1, 0], color=\"#5583A8\")\n",
        "    # محاسبه outliers\n",
        "    q1 = df[col_name].quantile(0.25)\n",
        "    q3 = df[col_name].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "\n",
        "    lower_outliers = df[col_name][df[col_name] < lower_bound]\n",
        "    upper_outliers = df[col_name][df[col_name] > upper_bound]\n",
        "    total_outliers = len(lower_outliers) + len(upper_outliers)\n",
        "    percent_outliers = 100 * total_outliers / len(df[col_name])\n",
        "    label_text = (\n",
        "        f\"Lower Outliers: {len(lower_outliers)}\\n\"\n",
        "        f\"Upper Outliers: {len(upper_outliers)}\\n\"\n",
        "        f\"Total: {total_outliers} ({percent_outliers:.1f}%)\"\n",
        "    )\n",
        "    patch = mpatches.Patch(color='skyblue', label=label_text)\n",
        "    ax[1, 0].legend(handles=[patch], fontsize=12, loc='upper left', bbox_to_anchor=(1.05, 1))\n",
        "    # پایان outliers\n",
        "    counts, bin_edges = np.histogram(df[col_name], bins=10, density=True)\n",
        "    pdf = counts / (sum(counts))\n",
        "    cdf = np.cumsum(pdf)\n",
        "    ax[1, 1] = plt.subplot(122)\n",
        "    plt.plot(bin_edges[1:], pdf, label='PDF')\n",
        "    plt.plot(bin_edges[1:], cdf, label='CDF')\n",
        "    plt.legend()\n",
        "    ax[0, 0].set_xticklabels([])\n",
        "    ax[1, 0].set_yticklabels([])\n",
        "    ax[0, 0].set_xlabel('')\n",
        "    ax[0, 0].set_ylabel('Count')\n",
        "    fig.suptitle(col_name, fontsize=30)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    info_df = pd.DataFrame.from_dict(info, orient='index', columns=[''])\n",
        "    print('=' * 18 + ' ' + col_name + ' ' + '=' * 18)\n",
        "    print(info_df)\n",
        "    print('=' * 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "774f62440eea40b5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.531356Z",
          "start_time": "2025-09-10T17:55:28.526328Z"
        },
        "id": "774f62440eea40b5"
      },
      "outputs": [],
      "source": [
        "def categorize_numerical_col(df, col_name, bins, bins_name):\n",
        "    new_col = f'{col_name}_categorized'\n",
        "    df[new_col] = pd.cut(df[col_name], bins=bins, labels=bins_name)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f908574ae95f43d",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.559546Z",
          "start_time": "2025-09-10T17:55:28.551707Z"
        },
        "id": "f908574ae95f43d"
      },
      "outputs": [],
      "source": [
        "def describe_categorical_col(df, col_name):\n",
        "    counts = pd.DataFrame(df[col_name].value_counts()).reset_index()\n",
        "    counts.columns = ['Group', 'Count']\n",
        "    total = sum(counts['Count'])\n",
        "    counts['%'] = (counts['Count'] / total * 100).round(2)\n",
        "\n",
        "    fig = px.pie(\n",
        "        counts,\n",
        "        names='Group',\n",
        "        values='Count',\n",
        "        title=f'<b>Distribution of {col_name} in each group</b>',\n",
        "        color='Group',\n",
        "        hole=0.3\n",
        "    )\n",
        "\n",
        "    fig.update_traces(\n",
        "        textposition='inside',\n",
        "        textinfo='percent+label',\n",
        "\n",
        "    )\n",
        "\n",
        "    fig.update_layout(\n",
        "        title_x=0.5,\n",
        "        legend_title_text='Groups',\n",
        "        font=dict(family=\"Arial, sans-serif\", size=14)\n",
        "    )\n",
        "    fig.show()\n",
        "    print('=' * 18 + ' ' + col_name + ' ' + '=' * 18)\n",
        "    print(counts)\n",
        "    print('=' * 40)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bivar Plots"
      ],
      "metadata": {
        "id": "uMox4KnfVPr3"
      },
      "id": "uMox4KnfVPr3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c3ba5c42b6f6bd9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.674699Z",
          "start_time": "2025-09-10T17:55:28.668989Z"
        },
        "id": "3c3ba5c42b6f6bd9"
      },
      "outputs": [],
      "source": [
        "def describe_target_relationship(df, feature_col, target_col):\n",
        "    if df[feature_col].dtype in ['object', 'category']:\n",
        "        if df[target_col].dtype in ['object', 'category']:\n",
        "            describe_cat_cat_relationship(df, feature_col, target_col)\n",
        "        else:\n",
        "            describe_cat_num_relationship(df, feature_col, target_col)\n",
        "    else:\n",
        "        if df[target_col].dtype in ['object', 'category']:\n",
        "            describe_cat_num_relationship(df, target_col, feature_col)\n",
        "        else:\n",
        "            describe_num_num_relationship(df, feature_col, target_col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53cff02d81897380",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.648926Z",
          "start_time": "2025-09-10T17:55:28.637331Z"
        },
        "id": "53cff02d81897380"
      },
      "outputs": [],
      "source": [
        "def describe_cat_cat_relationship(df, col1, col2):\n",
        "    # جدول تطبیقی\n",
        "    contingency_table = pd.crosstab(df[col1], df[col2])\n",
        "    normalized = pd.crosstab(df[col1], df[col2], normalize='index')\n",
        "\n",
        "    # آزمون کای دو\n",
        "    chi2, p_value, dof, expected = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "    # ضریب کرامر V\n",
        "    n = contingency_table.sum().sum()\n",
        "    cramers_v = np.sqrt(chi2 / (n * (min(contingency_table.shape) - 1)))\n",
        "\n",
        "    info = {\n",
        "        'chi2_statistic': f'{chi2:.5f}',\n",
        "        'p_value': f'{p_value:.5f}',\n",
        "        'degrees_of_freedom': dof,\n",
        "        'cramers_v': f'{cramers_v:.5f}',\n",
        "        'association_strength': 'strong' if cramers_v > 0.3 else 'moderate' if cramers_v > 0.1 else 'weak',\n",
        "        'significant_association': p_value < 0.05\n",
        "    }\n",
        "\n",
        "    # رسم نمودار\n",
        "    fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # Heatmap of contingency table\n",
        "    sns.heatmap(contingency_table, annot=True, cbar=False ,fmt='d', cmap=['White'], ax=axs[0, 0], linecolor='lightgray', linewidths=0.7)\n",
        "    axs[0, 0].set_title(f'Contingency Table: {col1} vs {col2}')\n",
        "\n",
        "    # Stacked bar chart 100%\n",
        "    normalized.plot.bar(stacked=True, ax=axs[0, 1])\n",
        "    axs[0, 1].set_title(f'Stacked Bar: {col1} vs {col2}')\n",
        "    axs[0, 1].legend(title=col2, labels=['No', 'Yes'])\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Normalized heatmap (percentages)\n",
        "    sns.heatmap(normalized, annot=True, fmt='.2%', cbar=False, cmap=['White'], ax=axs[1, 0], linecolor='lightgray', linewidths=0.7)\n",
        "    axs[1, 0].set_title(f'Normalized Contingency Table')\n",
        "\n",
        "    # Count plots side by side\n",
        "    contingency_table.plot(kind='bar', ax=axs[1, 1])\n",
        "    axs[1, 1].set_title(f'Count Comparison')\n",
        "    axs[1, 1].legend(title=col2, labels=['No', 'Yes'])\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    print('=' * 15 + f' {col1} vs {col2} ' + '=' * 15)\n",
        "    print(\"Contingency Table:\")\n",
        "    print(contingency_table)\n",
        "    print(\"\\nChi-square Test Results:\")\n",
        "    info_df = pd.DataFrame.from_dict(info, orient='index', columns=[''])\n",
        "    print(info_df)\n",
        "    print('=' * 50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical test functions"
      ],
      "metadata": {
        "id": "5eQIZwd1U-gK"
      },
      "id": "5eQIZwd1U-gK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e4d0a8b062559a",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.590941Z",
          "start_time": "2025-09-10T17:55:28.580291Z"
        },
        "id": "15e4d0a8b062559a"
      },
      "outputs": [],
      "source": [
        "def stattest_num_num_relationship(df, col1, col2):\n",
        "    # آزمون نرمال بودن با شاپیرو\n",
        "    shapiro1_stat, shapiro1_p = stats.shapiro(df[col1])\n",
        "    shapiro2_stat, shapiro2_p = stats.shapiro(df[col2])\n",
        "\n",
        "    # تشخیص نرمال بودن (p > 0.05 یعنی نرمال)\n",
        "    is_normal1 = shapiro1_p > 0.05\n",
        "    is_normal2 = shapiro2_p > 0.05\n",
        "    both_normal = is_normal1 and is_normal2\n",
        "\n",
        "    # انتخاب آزمون مناسب\n",
        "    if both_normal:\n",
        "        # استفاده از پیرسون\n",
        "        corr_stat, p_value = stats.pearsonr(df[col1], df[col2])\n",
        "        test_used = 'Pearson'\n",
        "        correlation = corr_stat\n",
        "    else:\n",
        "        # استفاده از اسپیرمن\n",
        "        corr_stat, p_value = stats.spearmanr(df[col1], df[col2])\n",
        "        test_used = 'Spearman'\n",
        "        correlation = corr_stat\n",
        "\n",
        "    r2_score = correlation ** 2\n",
        "\n",
        "    info = {\n",
        "        'shapiro_p_col1': f'{shapiro1_p:.5f}',\n",
        "        'shapiro_p_col2': f'{shapiro2_p:.5f}',\n",
        "        'col1_normal': is_normal1,\n",
        "        'col2_normal': is_normal2,\n",
        "        'test_used': test_used,\n",
        "        'correlation': f'{correlation:.5f}',\n",
        "        'r_squared': f'{r2_score:.5f}',\n",
        "        'p_value': f'{p_value:.5f}',\n",
        "        'significant': p_value < 0.05,\n",
        "        'relationship_strength': 'strong' if abs(correlation) > 0.7 else 'moderate' if abs(\n",
        "            correlation) > 0.3 else 'weak',\n",
        "        'relationship_direction': 'positive' if correlation > 0 else 'negative'\n",
        "    }\n",
        "\n",
        "    # رسم نمودار\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "    fig.suptitle(f'{col1} vs {col2} - {test_used} Correlation', fontsize=14)\n",
        "\n",
        "    # Scatter Plot\n",
        "    axes[0].scatter(df[col1], df[col2],\n",
        "                    s=60, alpha=0.7, color='blue', edgecolors='black', linewidth=0.5)\n",
        "    axes[0].set_title('Scatter Plot')\n",
        "    axes[0].set_xlabel(col1)\n",
        "    axes[0].set_ylabel(col2)\n",
        "    axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Hexbin Plot\n",
        "    axes[1].hexbin(df[col1], df[col2], gridsize=20, cmap='Blues', mincnt=1)\n",
        "    axes[1].set_title('Hexbin Plot')\n",
        "    axes[1].set_xlabel(col1)\n",
        "    axes[1].set_ylabel(col2)\n",
        "    axes[1].yaxis.set_label_position(\"right\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    info_df = pd.DataFrame.from_dict(info, orient='index', columns=[''])\n",
        "    print('=' * 15 + f' {col1} vs {col2} ' + '=' * 15)\n",
        "    print(info_df)\n",
        "    print('=' * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7001d9383df66d5",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.621473Z",
          "start_time": "2025-09-10T17:55:28.606122Z"
        },
        "id": "b7001d9383df66d5"
      },
      "outputs": [],
      "source": [
        "def stattest_cat_num_relationship(df, cat_col, num_col):\n",
        "    # محاسبه آمار\n",
        "    groups = df.groupby(cat_col)[num_col].describe()\n",
        "\n",
        "    # آزمون نرمال بودن با شاپیرو برای هر گروه\n",
        "    normality_results = {}\n",
        "    group_data = []\n",
        "    all_normal = True\n",
        "\n",
        "    for name, group in df.groupby(cat_col):\n",
        "        if len(group) >= 3:  # شاپیرو حداقل 3 داده نیاز داره\n",
        "            shapiro_stat, shapiro_p = stats.shapiro(group[num_col])\n",
        "            is_normal = shapiro_p > 0.05\n",
        "            normality_results[name] = {\n",
        "                'shapiro_p': f'{shapiro_p:.5f}',\n",
        "                'is_normal': is_normal\n",
        "            }\n",
        "            if not is_normal:\n",
        "                all_normal = False\n",
        "        else:\n",
        "            normality_results[name] = {\n",
        "                'shapiro_p': 'N/A (too few data)',\n",
        "                'is_normal': False\n",
        "            }\n",
        "            all_normal = False\n",
        "\n",
        "        group_data.append(group[num_col].values)\n",
        "\n",
        "    # انتخاب آزمون مناسب\n",
        "    if all_normal:\n",
        "        # استفاده از ANOVA معمولی\n",
        "        f_stat, p_value = stats.f_oneway(*group_data)\n",
        "        test_used = 'ANOVA'\n",
        "    else:\n",
        "        # استفاده از Welch's ANOVA\n",
        "        try:\n",
        "            from scipy.stats import alexandergovern\n",
        "            # اگر alexandergovern موجود نباشه، از kruskal استفاده می‌کنیم\n",
        "            result = alexandergovern(*group_data)\n",
        "            f_stat, p_value = result.statistic, result.pvalue\n",
        "            test_used = \"Welch's ANOVA\"\n",
        "        except ImportError:\n",
        "            # fallback به Kruskal-Wallis (non-parametric)\n",
        "            f_stat, p_value = stats.kruskal(*group_data)\n",
        "            test_used = 'Kruskal-Wallis (non-parametric)'\n",
        "\n",
        "    info = {\n",
        "        'test_used': test_used,\n",
        "        'all_groups_normal': all_normal,\n",
        "        'f_statistic': f'{f_stat:.5f}',\n",
        "        'p_value': f'{p_value:.5f}',\n",
        "        'significant_difference': p_value < 0.05,\n",
        "        'num_categories': df[cat_col].nunique(),\n",
        "        'total_observations': len(df)\n",
        "    }\n",
        "\n",
        "    # رسم نمودار\n",
        "    fig = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "    # Box plot\n",
        "    ax1 = plt.subplot(221)\n",
        "    sns.boxplot(data=df, x=cat_col, y=num_col)\n",
        "    ax1.set_title(f'{num_col} by {cat_col}')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Violin plot\n",
        "    ax2 = plt.subplot(222)\n",
        "    sns.violinplot(data=df, x=cat_col, y=num_col)\n",
        "    ax2.set_title(f'{num_col} Distribution by {cat_col}')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Bar plot of means\n",
        "    ax3 = plt.subplot(223)\n",
        "    means = df.groupby(cat_col)[num_col].mean().sort_values(ascending=False)\n",
        "    sns.barplot(x=means.index, y=means.values)\n",
        "    ax3.set_title(f'Mean {num_col} by {cat_col}')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    # Count plot of categories\n",
        "    ax4 = plt.subplot(224)\n",
        "    sns.countplot(data=df, x=cat_col)\n",
        "    ax4.set_title(f'Count of {cat_col}')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print('=' * 15 + f' {cat_col} vs {num_col} ' + '=' * 15)\n",
        "    print(\"Group Statistics:\")\n",
        "    print(groups)\n",
        "    print(f\"\\nNormality Test Results (Shapiro-Wilk):\")\n",
        "    for group_name, result in normality_results.items():\n",
        "        print(f\"{group_name}: p-value = {result['shapiro_p']}, Normal = {result['is_normal']}\")\n",
        "    print(f\"\\n{test_used} Test Results:\")\n",
        "    info_df = pd.DataFrame.from_dict(info, orient='index', columns=[''])\n",
        "    print(info_df)\n",
        "    print('=' * 50)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "657b01b3753c5b72",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.760225Z",
          "start_time": "2025-09-10T17:55:28.752110Z"
        },
        "id": "657b01b3753c5b72"
      },
      "outputs": [],
      "source": [
        "def categorical_tests(test_type=\"vs-target\", data=None, column=None, target=None, alpha=0.05):\n",
        "\n",
        "    if test_type == \"vs-target\":\n",
        "        con_table = pd.crosstab(data[column], data[target])\n",
        "        stat, p_value, degree, _ = stats.chi2_contingency(con_table)\n",
        "        result = {\n",
        "            \"categories vs target\":test_type, \"chi2_stat\": stat, \"p_value\": p_value,\n",
        "            \"degrees_of_freedom\": degree,\n",
        "            \"contingency_table\": con_table.to_dict()\n",
        "        }\n",
        "        print('='*48)\n",
        "        print(json.dumps(result, indent=3, sort_keys=False, default=str)) # using json.dumps for prettier printing\n",
        "        print('='*40)\n",
        "\n",
        "    elif test_type == \"vs-categories\":\n",
        "        categories = df[column].unique()\n",
        "        category_pairs = list(combinations(categories, 2))\n",
        "        result = []\n",
        "        for group1, group2 in category_pairs:\n",
        "            subset = df[df[column].isin([group1, group2])]\n",
        "            contingency_table = pd.crosstab(subset[column], subset[target])\n",
        "            chi2, p_value, degree, _ = stats.chi2_contingency(contingency_table)\n",
        "\n",
        "            if p_value < alpha:\n",
        "                print(f\"Significant difference between '{group1}' and '{group2}': \\nChi2={chi2:.4f}, p-value={p_value:.4f}\")\n",
        "            else:\n",
        "                print(f\"No significant difference between '{group1}' and '{group2}': \\nChi2={chi2:.4f}, p-value={p_value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KPI Plots"
      ],
      "metadata": {
        "id": "ymxFytTCSZup"
      },
      "id": "ymxFytTCSZup"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cf842ccd4a293bd9",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.787477Z",
          "start_time": "2025-09-10T17:55:28.778959Z"
        },
        "id": "cf842ccd4a293bd9"
      },
      "outputs": [],
      "source": [
        "def draw_heatmap_groups(df, group1, group2, kpi='Conversion Rate'):\n",
        "    if kpi not in ['Conversion Rate', 'CPC']:\n",
        "        raise ValueError('The KPI value should either be \"Conversion Rate\" or \"CPC\"')\n",
        "\n",
        "    tmp = get_grouped_data(df, [group1, group2])\n",
        "\n",
        "    heatmap_data = tmp.pivot_table(\n",
        "        index=group1,\n",
        "        columns=group2,\n",
        "        values=kpi\n",
        "    )\n",
        "    heatmap_data.fillna(0, inplace=True)\n",
        "    plt.figure(figsize=(18, 8))\n",
        "    sns.heatmap(\n",
        "        heatmap_data,\n",
        "        cmap='YlGnBu',\n",
        "        annot=True,\n",
        "        linewidths=0.7,\n",
        "        linecolor='lightgray'\n",
        "\n",
        "    )\n",
        "    plt.title(f'Heatmap of Conversion Rate by {group1}/{group2}', fontsize=18, weight='bold')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9fd4c727ee859d1",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-09-10T17:55:28.733320Z",
          "start_time": "2025-09-10T17:55:28.722017Z"
        },
        "id": "a9fd4c727ee859d1"
      },
      "outputs": [],
      "source": [
        "def kpi_barplot(df, group_col, kpi = 'Conversion Rate'):\n",
        "\n",
        "    if kpi not in ['Conversion Rate', 'CPC']:\n",
        "        raise ValueError('The KPI value should either be \"Conversion Rate\" or \"CPC\"')\n",
        "\n",
        "    tmp = get_grouped_data(df, group_col)\n",
        "\n",
        "    fig = plt.figure(figsize=(12, 7))\n",
        "    ax = sns.barplot(\n",
        "        data=tmp,\n",
        "        x=group_col,\n",
        "        y=kpi,\n",
        "        palette='viridis')\n",
        "    ax.set_title(f'{kpi} by {group_col}')\n",
        "\n",
        "    for p in ax.patches:\n",
        "        string = f'{p.get_height():.2f}%' if kpi == 'Conversion Rate' else f'{p.get_height():.4f}$'\n",
        "        ax.annotate(string,\n",
        "                    (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                    ha='center', va='center',\n",
        "                    fontsize=11, color='black',\n",
        "                    xytext=(0, 10),\n",
        "                    textcoords='offset points')\n",
        "    plt.show()\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}